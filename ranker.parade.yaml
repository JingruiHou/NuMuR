# model
seed: 10
bert_pretrained_model: distilbert-base-uncased
parade_aggregate_layers: 2
parade_aggregate_type: tf
idcm_chunk_size: 50
idcm_overlap: 7
padding_idx: 0
bert_trainable: True
dual_encoder: False
batch_size: 32
prediction_batch_size: 32
epochs: 3
distil_epochs: 20
learning_rate: 0.000007
colbert_compression_dim: 768
dropout: 0.0
return_vecs: False

unk_token: 0
query_max_len: 20
target_max_len: 200
model_type: parade
model_name: Parade
from_self.config: True
